{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Faster-RCNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_NmdOBASd0gk","colab_type":"code","outputId":"15aafd6f-945b-4c84-f487-2afa897d6982","executionInfo":{"status":"ok","timestamp":1585777375129,"user_tz":240,"elapsed":2457,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WKP7aKE3egO0","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import random\n","import time\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.transforms as transforms\n","import torchvision.models\n","from torchvision.models.detection.rpn import AnchorGenerator\n","from torchvision.models.detection import FasterRCNN\n","\n","path = \"/content/drive/My Drive/APS360 Project/v6-dataset/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3qefCpWfCpF","colab_type":"code","outputId":"fc985b06-bdf9-489f-8dab-2114d01e76ae","executionInfo":{"status":"ok","timestamp":1585777375392,"user_tz":240,"elapsed":2669,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if torch.cuda.is_available():\n","    print(\"CUDA activated\")\n","    use_cuda = True\n","    device = torch.device(\"cuda\")\n","    \n","else:\n","    print(\"Using CPU\")\n","    device = \"cpu\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["CUDA activated\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kjpkkOyefgUc","colab_type":"code","colab":{}},"source":["# These ae the classes we will be training in our model\n","\n","classes = [\"Apple\",\n","           \"Bagel\",\n","           \"Banana\",\n","           \"Bread\",\n","           \"Broccoli\",\n","           \"Burrito\",\n","           \"Carrot\",\n","           \"Cheese\",\n","           \"Coffee\",\n","           \"Cookie\",\n","           \"Cucumber\",\n","           \"Egg (Food)\",\n","           \"French fries\",\n","           \"Grape\",\n","           \"Hamburger\",\n","           \"Hot dog\",\n","           \"Juice\",\n","           \"Lemon\",\n","           \"Lobster\",\n","           \"Muffin\",\n","           \"Orange\",\n","           \"Pancake\",\n","           \"Pasta\",\n","           \"Pear\",\n","           \"Pizza\",\n","           \"Potato\",\n","           \"Salad\",\n","           \"Sandwich\",\n","           \"Strawberry\",\n","           \"Taco\",\n","           \"Tomato\",\n","           \"Waffle\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Z3xZXWziESB","colab_type":"code","colab":{}},"source":["def dataloader(filePath='clean-train-id.csv', batch_size=8, normalize=True):\n","    \n","    # Load csv and shuffle\n","    headers = pd.read_csv(os.path.join(path, filePath))\n","    headers = headers.sample(frac=1)\n","    transform = transforms.ToTensor()\n","    if normalize:\n","        transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","    \n","    # Make tensor of images, (labels and bbox)\n","    for i in range(0, len(headers.filePath), batch_size):\n","        imgs, label = [], []\n","        \n","        for j in range(batch_size):\n","\n","            img = Image.open(headers.filePath[i+j]).convert('RGB')\n","            w, h = img.size\n","            img = transform(img).cuda()\n","            imgs.append(img)\n","\n","            # Add labels to the dictionary\n","            boxes_dict = {}\n","            boxes_dict['boxes'] = torch.tensor([[headers.XMin[i+j] * w, \n","                                                 headers.YMin[i+j] * h, \n","                                                 headers.XMax[i+j] * w, \n","                                                 headers.YMax[i+j] * h]]).cuda()\n","            boxes_dict['labels'] = torch.tensor([classes[headers.Class_Description[i+j]]]).cuda()\n","\n","            label.append(boxes_dict)\n","        \n","        yield imgs, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zy3Sxjmv0Mtz","colab_type":"code","colab":{}},"source":["def get_train_acc_end(model, batch_size=6):\n","    s_losses = []\n","    tr_idx = 0\n","    correct = 0\n","    total = 0\n","    \n","    with torch.no_grad():\n","        imported = dataloader(filePath='clean-train-id.csv', batch_size=batch_size, normalize=True)\n","        \n","        for img, box in imported:\n","            if model(img)[0]['labels'].tolist()!=[]:\n","                predict = model(img)[0]\n","                find_idx = 0\n","\n","                for each in range(predict['labels'].shape[0]):\n","\n","                    if predict['labels'].tolist()[each]==box['labels'].tolist()[0]:\n","                        correct += 1\n","                        find_idx = each\n","                        break\n","                        \n","                out = predict['labels'][find_idx]\n","                resize_box = np.array(predict['boxes'][find_idx].tolist())\n","\n","            total += 1\n","            tr_idx += 1\n","    \n","    return correct/total\n","    \n","def get_val_loss_acc(val_model, batch_size=4):\n","    s_losses = []\n","    val_idx = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        val_model = val_model.train()    \n","        imported = dataloader(filePath='clean-validation-id.csv', batch_size=batch_size, normalize=True)\n","        \n","        for img, box in imported:\n","            loss_dict = val_model(img,box)\n","            losses = sum(loss for loss in loss_dict.values())\n","            s_losses.append(losses/batch_size)\n","            del loss_dict\n","            val_model = val_model.eval()\n","\n","            if val_model(img)[0]['labels'].tolist()!=[]:\n","                predict =  val_model(img)[0]\n","                find_idx = 0\n","\n","                for each in range(predict['labels'].shape[0]):\n","                    if predict['labels'].tolist()[each]==box['labels'].tolist()[0]:\n","                        correct += 1\n","                        find_idx = each\n","                        break\n","                        \n","                out = predict['labels'][find_idx]\n","                resize_box = np.array(predict['boxes'][find_idx].tolist())\n","\n","            total += 1\n","            val_idx += 1\n","            val_model = val_model.train()\n","\n","    return [sum(s_losses)/len(s_losses), correct/total]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rIdLx_IbJO1A","colab_type":"code","colab":{}},"source":["# Training Code (from a checkpoint)\n","def train_net_continue(model, batch_size=4, num_epochs=50, learning_rate=0.0001,\n","                      weight_decay=0.0002, lr_decay=4, ep=0, ck=0):\n","    \n","    model_path = f\"bs{batch_size}_lr{learning_rate}_epoch{ep}_checkpoint_{ck}\"\n","    checkpoint = torch.load(os.path.join(path, 'faster-rcnn-checkpoints/')+ model_path+'.pth')\n","\n","    start_time = time.time()\n","    torch.manual_seed(1000)\n","    params = [p for p in model.parameters() if p.requires_grad]\n","    optimizer = optim.Adam(params, lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Load states from the checkpoint\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    checkpoint = checkpoint['checkpoint']+1\n","    model = model.cuda(0)\n","    model = model.train()\n","    start_time = time.time()\n","    del checkpoint                                                                     \n","\n","    iter_acc = []\n","    iter_loss = []\n","    for epoch in range(ep+1, num_epochs):\n","        file_idx = 0\n","        data = dataloader(batch_size=batch_size)\n","\n","        for batch_img, batch_box in data:\n","            batch_box_cp = batch_box.copy()\n","            loss_dict = model(batch_img, batch_box)\n","            losses = sum(loss for loss in loss_dict.values())\n","            optimizer.zero_grad()\n","            losses.backward()\n","            optimizer.step()\n","            iter_loss.append(float(losses)/batch_size)\n","            i += 1\n","            print(\"\\n\")\n","\n","            file_idx += 1\n","            if file_idx%1000==0:\n","                # Note: Compute accuracy and loss again at the checkpoint since the initial training was screwed up \n","                model_path = \"bs{0}_lr{1}_epoch{2}_checkpoint_{3}\".format(batch_size,learning_rate,epoch,checkpoint)\n","                torch.save({\n","                    'checkpoint': checkpoint,\n","                    'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'loss': iter_loss,\n","                    }, os.path.join(path, 'faster-rcnn-checkpoints/')+ model_path+'.pth')\n","\n","                checkpoint += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kU6B2RU3orsu","colab_type":"code","colab":{}},"source":["anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 200),), aspect_ratios=((0.5, 1.0, 2.0),)) # follow documentation\n","backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n","backbone.out_channels = 1280 # documentation\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0], output_size=7, sampling_ratio=2)\n","rcnn1 = FasterRCNN(backbone,num_classes=32,rpn_anchor_generator=anchor_generator,box_roi_pool=roi_pooler).cuda(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMPVtjBniA8z","colab_type":"code","colab":{}},"source":["train_net_continue(rcnn1, batch_size=6, num_epochs=10, learning_rate=0.0001, \n","                   weight_decay=0.0001, ep=5, ck=28)\n","\n","# Note: Checkpoints have been deleted since they were taking too much\n","#       memory. Only the model checkpoint used for testing, and the last epoch\n","#       were saved"],"execution_count":0,"outputs":[]}]}